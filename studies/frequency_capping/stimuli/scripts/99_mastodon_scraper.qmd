---
title: 'DICE'
subtitle: "How Much Is Enough? Exploring Frequency Capping in Social Media Advertising"
author:
- name: Hauke Roggenkamp
  email: Hauke.Roggenkamp@unisg.ch
  orcid: 0009-0005-5176-4718
  corresponding: true
  affiliations:
    - name: Institute of Behavioral Science and Technology, University of St. Gallen
      address: Torstrasse 25
      city: St. Gallen
      country: Switzerland
      postal-code: 9000
date: now
date-format: long
format: 
  html:
    embed-resources: true
    theme: cosmo
    code-line-numbers: true
toc: false
number-sections: false
fig-cap-location: top
execute:
  echo: true
  warning: false
jupyter: python3
bibliography: ../../../../documentation/references.bib
---

```{python}
# !mkdir env
# !python3 -m venv env
# !source env/bin/activate
# !python3 -m pip install pandas requests pillow
```


```{python}
!export PATH="/Users/haukeroggenkamp/TechX Dropbox/Hauke Roggenkamp/oFeeds/env/bin:$PATH"
!echo $PATH  # Check if the path is set correctly
!which python  # Verify again
!which pip  # Verify again
```

```{python}
# !python3 -m pip install snscrape
```


```{python}
import json
import requests
import pandas as pd
from datetime import datetime, timedelta
```

[Thanks!](https://jrashford.com/2023/02/13/how-to-scrape-mastodon-timelines-using-python-and-pandas/)

```{python}
#| eval: false
URL = 'https://mastodon.social/api/v1/timelines/public'
params = {
    'limit': 40
}

since = pd.Timestamp('now', tz='utc') - pd.DateOffset(hour=1)
is_end = False

results = []

while True:
    r = requests.get(URL, params=params)
    toots = json.loads(r.text)

    if len(toots) == 0:
        break
    
    for t in toots:
        timestamp = pd.Timestamp(t['created_at'], tz='utc')
        if timestamp <= since:
            is_end = True
            break
            
        results.append(t)
    
    if is_end:
        break
    
    max_id = toots[-1]['id']
    params['max_id'] = max_id
    
df = pd.DataFrame(results)

```

```{python}
# Set up the initial parameters
URL = 'https://mastodon.social/api/v1/timelines/public'
search_query = 'tdf2024'  # Specific topic to search for
params = {
    'limit': 40  # Increase if needed
}

# Adjust the timeframe (e.g., last 30 days)
since = pd.Timestamp('now', tz='utc') - pd.DateOffset(days=30)
is_end = False

results = []

# Main loop to scrape data
while True:
    r = requests.get(URL, params=params)
    if r.status_code != 200:
        print(f"Error: {r.status_code}")
        break

    toots = json.loads(r.text)

    if len(toots) == 0:
        break
    
    for t in toots:
        timestamp = pd.Timestamp(t['created_at'], tz='utc')
        if timestamp <= since:
            is_end = True
            break
        
        # Check if the content contains the search query
        if search_query.lower() in t['content'].lower():
            results.append(t)
    
    if is_end:
        break
    
    max_id = toots[-1]['id']
    params['max_id'] = max_id

df = pd.DataFrame(results)

# Display the DataFrame
print(df)

# Optionally, save the DataFrame to a CSV file
df.to_csv('tour_de_france_2024_mastodon_toots.csv', index=False)

```




```{python}
#| eval: false
import snscrape.modules.mastodon as mastodon

query = 'tdf2024'
max_results = 100

scraper = mastodon.MastodonTootsScraper(query)
for i, toot in enumerate(scraper.get_items(), start=1):
    print(toot)
    if i >= max_results:
        break
```


